{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd5U49YmCvZC"
      },
      "source": [
        "# Workshop Context and Objectives\n",
        "\n",
        "This notebook is a hands-on workshop exercise demonstrating how to build a workflow from remote sensing and climate data to estimating missing spatio-temporal information using an analogue approach.\n",
        "\n",
        "## Context\n",
        "\n",
        "<details>\n",
        "<summary><b>Details</b></summary>\n",
        "\n",
        "Suppose we want to run a fully distributed hydrological model over the Volta River Basin. Such models require continuous daily inputs over long time periods, but in many regions observational datasets are incomplete, temporally sparse, or unavailable for recent years. To overcome this limitation, we will use a data-driven analogue method to generate the missing information needed to run the model.\n",
        "\n",
        "<div style=\"display:flex; gap:10px;\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/LoicGerber/synthetic_data_generation_workshop/52acd5850ad2311637ecf5704099c15e947f975e/isohyets.png\" width=\"35%\">\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/LoicGerber/synthetic_data_generation_workshop/52acd5850ad2311637ecf5704099c15e947f975e/dem.png\" width=\"34.8%\">\n",
        "\n",
        "</div>\n",
        "\n",
        "In this workshop, we will use GLEAM evapotranspiration data as our target variable. The goal is to learn the relationships between climate conditions and evapotranspiration from this reference dataset, and then generate synthetic images that statistically and spatially resemble GLEAM. To achieve this, we will use ERA5-Land temperature and precipitation as predictor variables, allowing us to reconstruct realistic evapotranspiration fields even when observations are missing.\n",
        "\n",
        "</details>\n",
        "\n",
        "## Part 1 - Accessing, downloading, and visualizing data\n",
        "\n",
        "<details>\n",
        "<summary><b>Details</b></summary>\n",
        "\n",
        "In the first part, we focus on data acquisition and preprocessing:\n",
        "- Access remote sensing and reanalysis data directly from Google Earth Engine (GEE).\n",
        "- Download Actual Evapotranspiration (AET) from the WaPOR Level 1 product (FAO).\n",
        "- Download daily climate predictors (precipitation and temperature) from ERA5-Land.\n",
        "- Spatially subset all datasets to the Volta River Basin using HydroSHEDS geometries.\n",
        "- Convert GEE ImageCollections into local NumPy arrays for simple python handling.\n",
        "- Save and reload processed datasets efficiently using compressed .npz files for reproducibility.\n",
        "- Visualize AET, precipitation, and temperature maps for qualitative inspection.\n",
        "\n",
        "</details>\n",
        "\n",
        "## Part 2 – kNN-based analogue modeling: method understanding and validation\n",
        "\n",
        "<details>\n",
        "<summary><b>Details</b></summary>\n",
        "\n",
        "This second part focuses on understanding the kNN-based analogue method through a simple, step-by-step demonstration. Following this illustrative example, the method is applied to reconstruct three full years of daily data within a validation framework, allowing for qualitative and quantitative assessment of its performance.\n",
        "- Load pre-processed NetCDF datasets of ET (target), precipitation, and temperature (predictors) clipped to the Volta Basin.\n",
        "- Ensure temporal alignment of predictors and target.\n",
        "- Optionally subset the spatial domain for faster computation.\n",
        "- Construct covariate features, including lagged predictors (*climate window*), to capture temporal dynamics.\n",
        "- Split the dataset into training and testing periods based on years.\n",
        "- Apply k-nearest neighbors (kNN) regression, where each unobserved ET image is estimated by finding the most similar historical climate “analogues.”\n",
        "- Visualize predicted versus observed ET maps for qualitative assessment.\n",
        "- Perform quantitative evaluation using Root Mean Squared Error (RMSE) over space and time.\n",
        "\n",
        "</details>\n",
        "\n",
        "## Part 3 – kNN-based analogue modeling: production run for 2021–2025\n",
        "\n",
        "<details>\n",
        "<summary><b>Details</b></summary>\n",
        "\n",
        "In this final part, we move from method validation to a full production run, applying the kNN-based analogue approach to estimate daily ET for the period 2021–2025, using all available historical observations up to 2020 as training data.\n",
        "\n",
        "Key steps include:\n",
        "- Prepare training datasets from ET (target) and climate predictors (precipitation and temperature) for all available historical data.\n",
        "- Apply the kNN analogue method to generate daily ET estimates for 2021–2025.\n",
        "- Compute _analogue-based uncertainty_ for each generated day, defined as the weighted standard deviation across the k nearest analogues.\n",
        "- Visualize daily ET reconstructions and their uncertainty.\n",
        "- Save the production datasets in both NetCDF and compressed `.npz` formats.\n",
        "- Copy final outputs to Google Drive for long-term storage and reproducibility.\n",
        "\n",
        "</details>\n",
        "\n",
        "## Learning Outcomes\n",
        "\n",
        "<details>\n",
        "<summary><b>Details</b></summary>\n",
        "\n",
        "By the end of this workshop, participants will be able to:\n",
        "1. Access and process geospatial datasets from GEE and local NetCDF files.\n",
        "2. Handle spatio-temporal data using `NumPy` and `xarray` efficiently.\n",
        "3. Apply masking and subsetting to focus on a specific river basin.\n",
        "4. Understand and implement a kNN-based analogue approach for estimating missing or unobserved images.\n",
        "5. Validate analogue-based reconstructions using visual diagnostics and RMSE.\n",
        "6. Apply the same method in a production setting to temporally disaggregate remote sensing products.\n",
        "7. Build reproducible workflows that integrate data acquisition, preprocessing, modeling, validation, and production runs.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMJng0viTSk7"
      },
      "source": [
        "## Import libraries and define helper functions\n",
        "\n",
        "\n",
        "> **Note:** this block must be run, but we will not look into it in details.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRDtD3tzUhq_"
      },
      "source": [
        "In this first step, we import all Python libraries required throughout the notebook. Key libraries include:\n",
        "- `ee` and `geemap` for interacting with Google Earth Engine\n",
        "- `NumPy` and `xarray` for numerical data handling\n",
        "- `matplotlib` for visualization\n",
        "- `scikit-learn` for kNN regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuqDZSK1CKqM"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import ee\n",
        "import geemap\n",
        "import numpy as np\n",
        "from google.colab import files, drive\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITQ0u3fCTUyA"
      },
      "source": [
        "### Converting ImageCollections to NumPy arrays\n",
        "\n",
        "GEE datasets are stored as ImageCollections, which must be converted into local arrays for analysis.\n",
        "\n",
        "This helper function:\n",
        "- Iterates over all images in an ImageCollection\n",
        "- Clips each image to the Volta Basin\n",
        "- Converts each image to a NumPy array\n",
        "- Stores acquisition dates alongside the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQAuduPpTWg7"
      },
      "outputs": [],
      "source": [
        "# Function to convert an Earth Engine ImageCollection into a NumPy array\n",
        "def ee_ic_to_numpy(ic, region, scale):\n",
        "    \"\"\"\n",
        "    Convert an Earth Engine ImageCollection to a local NumPy array with corresponding dates.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ic : ee.ImageCollection\n",
        "        The Earth Engine ImageCollection to download.\n",
        "    region : ee.Geometry\n",
        "        The spatial region to clip each image.\n",
        "    scale : float\n",
        "        The spatial resolution (in meters) for the output array.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np_array : np.ndarray (time, y, x)\n",
        "        Stacked NumPy array of all images in the collection.\n",
        "    dates : list of str\n",
        "        Acquisition dates corresponding to each image (YYYY-MM-DD).\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert ImageCollection to a server-side list for iteration\n",
        "    img_list = ic.toList(ic.size())\n",
        "\n",
        "    # Force server-side evaluation to get number of images\n",
        "    n = img_list.size().getInfo()\n",
        "    print(f\"    Downloading {n} daily images...\")\n",
        "\n",
        "    # Initialize lists to hold arrays and dates\n",
        "    arrays = []\n",
        "    dates = []\n",
        "\n",
        "    # If the collection is empty, return empty outputs\n",
        "    if n == 0:\n",
        "        return np.array([]), [], np.array([])\n",
        "\n",
        "    # Loop over each image in the collection\n",
        "    for i in tqdm(range(n), desc=\"      Progress\"):\n",
        "\n",
        "        # Retrieve individual image from server-side list\n",
        "        img = ee.Image(img_list.get(i))\n",
        "\n",
        "        # Extract the image acquisition date as a string\n",
        "        date = ee.Date(img.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
        "\n",
        "        # Convert EE image to NumPy array and clip to the specified region\n",
        "        arr = geemap.ee_to_numpy(img.clip(region), scale=scale)\n",
        "\n",
        "        # Append array and date to lists\n",
        "        arrays.append(arr)\n",
        "        dates.append(date)\n",
        "\n",
        "    # Stack all images along a new time dimension\n",
        "    np_array = np.stack(arrays)\n",
        "\n",
        "    # Return the stacked array and corresponding dates\n",
        "    return np_array, dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOl4RmBdQZqw"
      },
      "source": [
        "## 1.1 - Authenticate and initialize Google Earth Engine\n",
        "Before accessing GEE datasets, we must authenticate and initialize the Earth Engine API.\n",
        "- `ee.Authenticate()` opens an authentication prompt (only required once per session)\n",
        "- `ee.Initialize()` establishes the connection to GEE\n",
        "\n",
        "> **IMPORTANT**: You MUST specify a project name. Otherwise, GEE access may fail.\n",
        "\n",
        "How to find your project ID:\n",
        "1. Go to https://code.earthengine.google.com\n",
        "2. Look at the top-right corner, where your name and photo are\n",
        "3. The name displayed is your Project ID\n",
        "4. Paste it below\n",
        "\n",
        "If you do not have a project yet, you can create one from the Earth Engine Code Editor in a few clicks. Follow the steps listed here: https://developers.google.com/earth-engine/guides/access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpD5015S0Eh8"
      },
      "outputs": [],
      "source": [
        "ee.Authenticate()\n",
        "ee.Initialize(project='lgerber') # <----------- UPDATE WITH YOUR PROJECT ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDpPVdHSQlYH"
      },
      "source": [
        "## 1.2 - Define temporal and spatial parameters\n",
        "Here we define:\n",
        "- The time period of interest\n",
        "- The spatial resolution of each dataset\n",
        "\n",
        "Why different resolutions?\n",
        "- WaPOR AET is available at ~1km\n",
        "- ERA5-Land climate variables are available at coarser (~11 km) resolution\n",
        "\n",
        "This scale mismatch is not an issue for analogue-based modeling. With this, we take advantage of coarse-resolution predictors (for computational efficiency) to generate a fine-scale target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdA5Kew7CN5r"
      },
      "outputs": [],
      "source": [
        "# Set parameters\n",
        "START_DATE       = '2025-01-01'\n",
        "END_DATE         = '2025-01-31'\n",
        "SCALE_TARGET     = 1000   # ~ 1 km (WaPOR resolution)\n",
        "SCALE_PREDICTORS = 11132  # ~11 km (ERA5-Land resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcy-nXMDRZOa"
      },
      "source": [
        "## 1.3 - Load and visualize the Volta Basin geometry\n",
        "\n",
        "We now load the Volta River Basin boundary using the HydroSHEDS basin dataset and create a binary mask.\n",
        "\n",
        "Steps performed:\n",
        "\n",
        "1. Load basin polygons from HydroSHEDS\n",
        "2. Select the Volta Basin using its unique basin ID\n",
        "3. Convert the basin polygon into a raster mask\n",
        "\n",
        "To verify that the correct basin is selected, we display it on an interactive map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYcU4bWbCPnC"
      },
      "outputs": [],
      "source": [
        "# Load the Volta Basin geometry and create a mask\n",
        "basins      = ee.FeatureCollection(\"WWF/HydroSHEDS/v1/Basins/hybas_3\")\n",
        "volta_basin = basins.filter(ee.Filter.eq('HYBAS_ID', 1030023300)).geometry()\n",
        "mask_img    = ee.Image().byte().paint(volta_basin, 1)\n",
        "\n",
        "mask_target = geemap.ee_to_numpy(mask_img, region=volta_basin, scale=SCALE_TARGET)\n",
        "\n",
        "# Visualize the Volta Basin on an interactive map\n",
        "Map = geemap.Map(center=[8, -1], zoom=6)  # Approximate center of Volta Basin\n",
        "Map.add_basemap(\"SATELLITE\")\n",
        "Map.addLayer(volta_basin, {'color': 'red'}, \"Volta Basin Boundary\")\n",
        "Map.addLayerControl()\n",
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC4rYRXBR3H4"
      },
      "source": [
        "## 1.4 - Download WaPOR Actual Evapotranspiration (AET)\n",
        "\n",
        "We now download daily Actual Evapotranspiration from the WaPOR Level 1 product.\n",
        "\n",
        "Processing steps:\n",
        "- Filter by date\n",
        "- Select the AET band\n",
        "- Convert units from tenths of mm/day to mm/day\n",
        "- Apply the Volta Basin mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_ZFpzeBCVDc"
      },
      "outputs": [],
      "source": [
        "# Download WaPOR Actual Evapotranspiration (AET)\n",
        "aet_ic = (\n",
        "    ee.ImageCollection('FAO/WAPOR/3/L1_AETI_D')\n",
        "    .filterDate(START_DATE, END_DATE)\n",
        "    .select('L1-AETI-D')\n",
        "    .map(lambda img: img.divide(10).copyProperties(img, img.propertyNames()))\n",
        ")\n",
        "print(\"Downloading WaPOR Actual ET...\")\n",
        "aet, aet_dates = ee_ic_to_numpy(aet_ic, volta_basin, SCALE_TARGET)\n",
        "aet = np.where(mask_target == 1, aet, np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbVa28E-SAxC"
      },
      "source": [
        "## 1.5 - Download ERA5-Land temperature and precipitation\n",
        "We next download daily climate predictors from ERA5-Land.\n",
        "\n",
        "### 1.5.1 Air temperature at 2 meters\n",
        "- Converted from Kelvin to degrees Celsius\n",
        "- Masked to valid land pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4PP84kCCXM6"
      },
      "outputs": [],
      "source": [
        "# Download ERA5-Land 2m Temperature\n",
        "temp_ic = (\n",
        "    ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR')\n",
        "    .filterDate(START_DATE, END_DATE)\n",
        "    .select('temperature_2m')\n",
        "    .map(lambda img: img.subtract(273.15).copyProperties(img, img.propertyNames()))  # Kelvin to °C\n",
        ")\n",
        "print(\"Downloading ERA5-Land 2m Temperature...\")\n",
        "temp, temp_dates = ee_ic_to_numpy(temp_ic, volta_basin, SCALE_PREDICTORS)\n",
        "mask = np.where(temp[0,:,:] != 0, 1, 0)\n",
        "temp = np.where(mask == 1, temp, np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwRHDE_xSY_d"
      },
      "source": [
        "### 1.5.2 Tatal daily precipitation\n",
        "- Converted from meters/day to mm/day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM7A-t95Caz8"
      },
      "outputs": [],
      "source": [
        "# Download ERA5-Land Precipitation\n",
        "prec_ic = (\n",
        "    ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR')\n",
        "    .filterDate(START_DATE, END_DATE)\n",
        "    .select('total_precipitation_sum')  # meters/day\n",
        "    .map(lambda img: img.multiply(1000).copyProperties(img, img.propertyNames()))  # mm/day\n",
        ")\n",
        "print(\"Downloading ERA5-Land Precipitation...\")\n",
        "prec, prec_dates = ee_ic_to_numpy(prec_ic, volta_basin, SCALE_PREDICTORS)\n",
        "prec = np.where(mask == 1, prec, np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6xjHMvOSdOP"
      },
      "source": [
        "## 1.6 - Save the processed dataset\n",
        "\n",
        "To avoid repeated downloads, we save all arrays and metadata into a compressed NumPy archive (.npz)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRtiPF9gCds1"
      },
      "outputs": [],
      "source": [
        "# Save the downloaded data\n",
        "name = \"example_Volta_data\"    # <-------------------------------- CHANGE FILE NAME HERE\n",
        "np.savez_compressed(\n",
        "    f'{name}.npz',\n",
        "    aet=aet, aet_dates=aet_dates,\n",
        "    precip=prec, precip_dates=prec_dates,\n",
        "    temp=temp, temp_dates=temp_dates\n",
        ")\n",
        "print(\"All data downloaded and saved.\")\n",
        "\n",
        "# Trigger browser download to the Downloads folder\n",
        "files.download(f'{name}.npz')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NsDNXipSovU"
      },
      "source": [
        "We then also save a copy to Google Drive for persistent storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzEriYcSGCWs"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define data path (folder + file)\n",
        "save_dir  = '/content/drive/MyDrive/SyntheticSatDataWorkshop2026' # <-------------------------------- CHANGE DIRECTORY HERE\n",
        "data_path = os.path.join(save_dir, f'{name}.npz')\n",
        "\n",
        "# Create folder if it does not exist\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Copy file to Google Drive\n",
        "!cp example_Volta_data.npz \"$data_path\"     # <------------------------------------------------------ CHANGE FILE NAME HERE\n",
        "\n",
        "print(f\"File saved to Google Drive at: {data_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWipToVvC2Jq"
      },
      "source": [
        "## 1.7 - Reloading the saved data\n",
        "\n",
        "This section demonstrates how to reload the dataset without re-running Earth Engine queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXpa1LwlCjZU"
      },
      "outputs": [],
      "source": [
        "# Load dataset from Google Drive\n",
        "data = np.load(data_path, allow_pickle=True)\n",
        "\n",
        "aet  = data['aet']\n",
        "prec = data['precip']\n",
        "temp = data['temp']\n",
        "\n",
        "aet_dates  = data['aet_dates']\n",
        "prec_dates = data['precip_dates']\n",
        "temp_dates = data['temp_dates']\n",
        "\n",
        "print(f\"AET shape: {aet.shape}, Precip shape: {prec.shape}, Temp shape: {temp.shape}\")\n",
        "print(f\"Dates: {aet_dates[0]} - {aet_dates[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dLQXsh5S2Ku"
      },
      "source": [
        "## 1.8 - Visual inspection of the datasets\n",
        "\n",
        "Before moving to modeling, it is crucial to visually inspect the data.\n",
        "\n",
        "This final section allows you to:\n",
        "- Select a specific date index\n",
        "- Compare spatial patterns of AET, precipitation, and temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1TwEEG8CmBA"
      },
      "outputs": [],
      "source": [
        "# Visual comparison of AET, Precipitation, and Temperature\n",
        "\n",
        "AET_dateIndex = 0   # <---- CHANGE VALUE HERE\n",
        "pre_dateIndex = 0   # <---- CHANGE VALUE HERE\n",
        "tem_dateIndex = 0   # <---- CHANGE VALUE HERE\n",
        "\n",
        "# Plotting\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18,6))\n",
        "\n",
        "im0 = axes[0].imshow(aet[AET_dateIndex,:,:], cmap='viridis', vmin=0, vmax=10)\n",
        "axes[0].set_title(f\"AET — {aet_dates[AET_dateIndex]}\")\n",
        "axes[0].axis('off')\n",
        "cbar0 = fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
        "cbar0.set_label(\"AET [mm/day]\")\n",
        "\n",
        "im1 = axes[1].imshow(prec[pre_dateIndex,:,:], cmap='Blues', vmin=0)\n",
        "axes[1].set_title(f\"Precipitation — {prec_dates[pre_dateIndex]}\")\n",
        "axes[1].axis('off')\n",
        "cbar0 = fig.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
        "cbar0.set_label(\"Precip [mm/day]\")\n",
        "\n",
        "im2 = axes[2].imshow(temp[tem_dateIndex,:,:], cmap='coolwarm', vmin=15, vmax=35)\n",
        "axes[2].set_title(f\"Temperature — {temp_dates[tem_dateIndex]}\")\n",
        "axes[2].axis('off')\n",
        "cbar0 = fig.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
        "cbar0.set_label(\"Maximum temperature [°C]\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NMJng0viTSk7"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}